from datetime import datetime
import logging
import os
import torch
import torch.nn.functional as F
from tqdm import tqdm
import sys
import argparse
import csv
import threading
from typing import Generator, Tuple, Union, Optional, List, Dict
import time
import random

import glob


from src.config import (
    LOG_LEVEL,
    DEFAULT_MODE,
    DEFAULT_RADIUS,
    DEFAULT_THRESHOLD,
    SPAWN_RADIUS,
    MAX_SLIME_CHUNKS,
    MAX_RADIUS,
    MIN_SEED,
    MAX_SEED,
    device,
    BLOCK_SIZE,
    PATTERN,
    PATTERN_FP16,
    USE_FP16,
    v1,
    v2,
    v3,
    v4,
    scrambler,
    multiplier,
    addend,
    mask,
)


MAX_LOG_FILES = 10  # æœ€å¤§ä¿ç•™æ—¥å¿—æ–‡ä»¶æ•°
RESULTS_DIR = "results"  # ç»“æœè¾“å‡ºç›®å½•
CHECKPOINT_FILE = "checkpoint.txt"  # æ–­ç‚¹æ–‡ä»¶
CHECKPOINT_FLUSH_INTERVAL = 100  # æ£€æŸ¥ç‚¹æ‰¹é‡å†™å…¥é—´éš”

# çº¿ç¨‹å®‰å…¨çš„ç»“æœæ”¶é›†å™¨
_results_lock = threading.Lock()
_results: List[Dict] = []
_processed_seeds: set = set()
_pending_checkpoints: List[int] = []
_verbose_output: bool = True
_count_only_mode: bool = False

# è®¡æ•°æ¨¡å¼ç»Ÿè®¡ï¼ˆä¸ä¿å­˜æ˜ç»†ç»“æœï¼‰
_count_only_stats_lock = threading.Lock()
_count_only_total_seeds: int = 0
_count_only_hit_seeds: int = 0
_count_only_best: Dict[int, int] = {}

# å•å—åæ ‡ç¼“å­˜ï¼ˆchunk_radius å›ºå®šæ—¶å¯å¤ç”¨ï¼Œå‡å°‘æ¯ä¸ª seed çš„ arange åˆ†é…å¼€é”€ï¼‰
_single_block_coord_cache: Dict[Tuple[int, str], Tuple[torch.Tensor, torch.Tensor]] = {}


def _device_cache_key(dev: torch.device) -> str:
    """ç”Ÿæˆè®¾å¤‡ç¼“å­˜é”®ã€‚"""
    return f"{dev.type}:{dev.index}"


def _get_single_block_coords(
    chunk_radius: int,
    device: torch.device,
) -> Tuple[int, int, torch.Tensor, torch.Tensor]:
    """è·å–å•å—å¿«é€Ÿè·¯å¾„æ‰€éœ€çš„åæ ‡å¼ é‡ï¼ˆå¸¦ç¼“å­˜ï¼‰ã€‚"""
    key = (chunk_radius, _device_cache_key(device))
    cached = _single_block_coord_cache.get(key)
    if cached is not None:
        x_coords, z_coords = cached
        return -chunk_radius, -chunk_radius, x_coords, z_coords

    x_start = -chunk_radius
    z_start = -chunk_radius
    x_end = chunk_radius + 1
    z_end = chunk_radius + 1

    x_block = torch.arange(x_start, x_end, dtype=torch.int32, device=device)
    z_block = torch.arange(z_start, z_end, dtype=torch.int32, device=device)
    x_coords = x_block.unsqueeze(0)
    z_coords = z_block.unsqueeze(1)

    _single_block_coord_cache[key] = (x_coords, z_coords)
    return x_start, z_start, x_coords, z_coords


def load_checkpoint() -> set:
    """
    åŠ è½½å·²å¤„ç†çš„ç§å­æ£€æŸ¥ç‚¹

    Returns:
        set: å·²å¤„ç†çš„ç§å­é›†åˆ
    """
    checkpoint_path = os.path.join(RESULTS_DIR, CHECKPOINT_FILE)
    if os.path.exists(checkpoint_path):
        try:
            with open(checkpoint_path, "r") as f:
                return set(int(line.strip()) for line in f if line.strip())
        except Exception:
            pass
    return set()


def save_checkpoint(seed: int) -> None:
    """
    ä¿å­˜å·²å¤„ç†çš„ç§å­åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶

    Args:
        seed: å·²å¤„ç†çš„ç§å­
    """
    with _results_lock:
        _processed_seeds.add(seed)
        _pending_checkpoints.append(seed)


def flush_checkpoints(force: bool = False) -> None:
    """
    æ‰¹é‡å†™å…¥æ£€æŸ¥ç‚¹ï¼Œå‡å°‘é¢‘ç¹ I/O

    Args:
        force: æ˜¯å¦å¼ºåˆ¶å†™å…¥ï¼ˆå¿½ç•¥æ‰¹é‡é˜ˆå€¼ï¼‰
    """
    with _results_lock:
        if not _pending_checkpoints:
            return
        if not force and len(_pending_checkpoints) < CHECKPOINT_FLUSH_INTERVAL:
            return

        to_write = _pending_checkpoints.copy()
        _pending_checkpoints.clear()

    os.makedirs(RESULTS_DIR, exist_ok=True)
    checkpoint_path = os.path.join(RESULTS_DIR, CHECKPOINT_FILE)
    with open(checkpoint_path, "a") as f:
        f.writelines(f"{seed}\n" for seed in to_write)


def set_verbose_output(enabled: bool) -> None:
    """è®¾ç½®æ˜¯å¦è¾“å‡ºè¯¦ç»†å‘½ä¸­æ—¥å¿—"""
    global _verbose_output
    _verbose_output = enabled


def is_verbose_output() -> bool:
    """è·å–æ˜¯å¦è¾“å‡ºè¯¦ç»†å‘½ä¸­æ—¥å¿—"""
    return _verbose_output


def set_count_only_mode(enabled: bool) -> None:
    """è®¾ç½®æ˜¯å¦å¯ç”¨ä»…è®¡æ•°æ¨¡å¼ï¼ˆä¸ä¿å­˜æ¯ä¸ªå‘½ä¸­æ˜ç»†ï¼‰"""
    global _count_only_mode
    _count_only_mode = enabled


def is_count_only_mode() -> bool:
    """è·å–æ˜¯å¦å¯ç”¨ä»…è®¡æ•°æ¨¡å¼"""
    return _count_only_mode


def clear_count_only_stats() -> None:
    """æ¸…ç©ºä»…è®¡æ•°æ¨¡å¼ç»Ÿè®¡æ•°æ®"""
    global _count_only_total_seeds, _count_only_hit_seeds
    with _count_only_stats_lock:
        _count_only_total_seeds = 0
        _count_only_hit_seeds = 0
        _count_only_best.clear()


def update_count_only_seed_best(seed: int, count: int) -> None:
    """æ›´æ–°æŸä¸ªç§å­çš„æœ€ä½³å‘½ä¸­è®¡æ•°"""
    with _count_only_stats_lock:
        prev = _count_only_best.get(seed)
        if prev is None or count > prev:
            _count_only_best[seed] = count


def finalize_count_only_seed(seed: int) -> None:
    """åœ¨ç§å­å¤„ç†ç»“æŸåæ±‡æ€»ç»Ÿè®¡"""
    global _count_only_total_seeds, _count_only_hit_seeds
    with _count_only_stats_lock:
        _count_only_total_seeds += 1
        if seed in _count_only_best:
            _count_only_hit_seeds += 1


def get_count_only_summary() -> Dict[str, Union[int, float]]:
    """è·å–ä»…è®¡æ•°æ¨¡å¼ç»Ÿè®¡æ‘˜è¦"""
    with _count_only_stats_lock:
        total = _count_only_total_seeds
        hit = _count_only_hit_seeds
        hit_rate = (hit / total) if total > 0 else 0.0
        best = max(_count_only_best.values()) if _count_only_best else 0
        return {
            "processed_seeds": total,
            "hit_seeds": hit,
            "hit_rate": hit_rate,
            "best_count": best,
        }


def _is_single_seed_mode(args: argparse.Namespace) -> bool:
    """æ ¹æ®å‘½ä»¤è¡Œå‚æ•°åˆ¤æ–­æ˜¯å¦å•ç§å­æ¨¡å¼"""
    if args.interactive:
        return False
    return (args.seed is not None) and (not args.multiple)


def should_warmup(args: argparse.Namespace) -> bool:
    """
    è‡ªåŠ¨é¢„çƒ­ç­–ç•¥ï¼š
    - æ˜ç¡® --no-warmup: ä¸é¢„çƒ­
    - å•ç§å­æ¨¡å¼é»˜è®¤ä¸é¢„çƒ­ï¼ˆä¼˜å…ˆé¦–ç»“æœå“åº”ï¼‰
    - å¤šç§å­æ¨¡å¼é»˜è®¤é¢„çƒ­ï¼ˆä¼˜å…ˆç¨³æ€ååï¼‰
    """
    if args.no_warmup:
        return False
    return not _is_single_seed_mode(args)


def clear_checkpoint() -> None:
    """æ¸…é™¤æ£€æŸ¥ç‚¹æ–‡ä»¶"""
    checkpoint_path = os.path.join(RESULTS_DIR, CHECKPOINT_FILE)
    if os.path.exists(checkpoint_path):
        os.remove(checkpoint_path)
    with _results_lock:
        _processed_seeds.clear()
        _pending_checkpoints.clear()


def add_result(seed: int, count: int, x: int, z: int) -> None:
    """
    çº¿ç¨‹å®‰å…¨åœ°æ·»åŠ ç»“æœï¼ˆå¼‚æ­¥å†™å…¥ï¼‰

    Args:
        seed: ä¸–ç•Œç§å­
        count: å²è±å§†åŒºå—æ•°
        x: æŒ‚æœºç‚¹ X åæ ‡
        z: æŒ‚æœºç‚¹ Z åæ ‡
    """
    result = {
        "seed": seed,
        "slime_chunks": count,
        "afk_x": x,
        "afk_z": z,
        "timestamp": datetime.now().isoformat()
    }
    with _results_lock:
        _results.append(result)


def add_results_batch(results: List[Dict]) -> None:
    """
    çº¿ç¨‹å®‰å…¨åœ°æ‰¹é‡æ·»åŠ ç»“æœ

    Args:
        results: ç»“æœå­—å…¸åˆ—è¡¨
    """
    if not results:
        return
    with _results_lock:
        _results.extend(results)


def save_results_to_csv(filename: Optional[str] = None) -> str:
    """
    ä¿å­˜ç»“æœåˆ° CSV æ–‡ä»¶

    Args:
        filename: æ–‡ä»¶åï¼Œå¦‚æœä¸º None åˆ™è‡ªåŠ¨ç”Ÿæˆ

    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    os.makedirs(RESULTS_DIR, exist_ok=True)

    if filename is None:
        filename = f"results_{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.csv"

    filepath = os.path.join(RESULTS_DIR, filename)

    with _results_lock:
        if not _results:
            return ""

        with open(filepath, "w", newline="", encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=["seed", "slime_chunks", "afk_x", "afk_z", "timestamp"])
            writer.writeheader()
            writer.writerows(_results)

    return filepath


def clear_results() -> None:
    """æ¸…ç©ºç»“æœåˆ—è¡¨"""
    with _results_lock:
        _results.clear()


def get_top_results(n: int = 10, deduplicate: bool = True) -> List[Dict]:
    """
    è·å–æ’åå‰ N çš„ç»“æœï¼ˆæŒ‰å²è±å§†åŒºå—æ•°æ’åºï¼‰

    Args:
        n: è¿”å›ç»“æœæ•°é‡
        deduplicate: æ˜¯å¦å»é‡ï¼ˆåŒä¸€ä½ç½®åªä¿ç•™æœ€é«˜åˆ†ï¼‰

    Returns:
        List[Dict]: æ’åºåçš„ç»“æœåˆ—è¡¨
    """
    with _results_lock:
        if not _results:
            return []

        if deduplicate:
            # æŒ‰ (seed, afk_x, afk_z) å»é‡ï¼Œä¿ç•™æœ€é«˜åˆ†
            unique_results = {}
            for r in _results:
                key = (r['seed'], r['afk_x'], r['afk_z'])
                if key not in unique_results or r['slime_chunks'] > unique_results[key]['slime_chunks']:
                    unique_results[key] = r
            sorted_results = sorted(unique_results.values(), key=lambda x: x['slime_chunks'], reverse=True)
        else:
            sorted_results = sorted(_results, key=lambda x: x['slime_chunks'], reverse=True)

        return sorted_results[:n]


def get_results_summary() -> Dict:
    """
    è·å–ç»“æœç»Ÿè®¡æ‘˜è¦

    Returns:
        Dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    with _results_lock:
        if not _results:
            return {'count': 0, 'max': 0, 'min': 0, 'avg': 0}

        counts = [r['slime_chunks'] for r in _results]
        return {
            'count': len(_results),
            'max': max(counts),
            'min': min(counts),
            'avg': sum(counts) / len(counts),
            'unique_seeds': len(set(r['seed'] for r in _results)),
        }


def cleanup_old_logs(log_dir: str = "log", max_files: int = MAX_LOG_FILES) -> None:
    """
    æ¸…ç†æ—§çš„æ—¥å¿—æ–‡ä»¶ï¼Œåªä¿ç•™æœ€æ–°çš„ max_files ä¸ª

    Args:
        log_dir: æ—¥å¿—ç›®å½•
        max_files: æœ€å¤§ä¿ç•™æ–‡ä»¶æ•°
    """
    log_files = glob.glob(os.path.join(log_dir, "*.log"))
    if len(log_files) > max_files:
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œåˆ é™¤æœ€æ—§çš„
        log_files.sort(key=os.path.getmtime)
        for old_file in log_files[:-max_files]:
            try:
                os.remove(old_file)
            except OSError:
                pass  # å¿½ç•¥åˆ é™¤å¤±è´¥


def init_logging() -> None:
    """
    åˆå§‹åŒ–æ—¥å¿—è®¾ç½®åŠç›®å½•ï¼Œå¹¶æ¸…ç†æ—§æ—¥å¿—
    """
    os.makedirs("log", exist_ok=True)
    cleanup_old_logs()
    logging.basicConfig(
        filename=f"log/{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}.log",
        level=LOG_LEVEL,
        format="%(asctime)s - %(levelname)s:\t\t%(message)s",
        encoding="UTF-8",
    )


def log_and_print(message: str) -> None:
    print(message)
    logging.info(message)


def parse_args() -> argparse.Namespace:
    """
    è§£æå‘½ä»¤è¡Œå‚æ•°

    Returns:
        argparse.Namespace: è§£æåçš„å‚æ•°
    """
    parser = argparse.ArgumentParser(
        description="Minecraft å²è±å§†åŒºå—è®¡æ•°å™¨ - å¯»æ‰¾æœ€ä½³å²è±å§†å†œåœºä½ç½®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python run.py                          # äº¤äº’å¼æ¨¡å¼
  python run.py -s 12345                 # æŒ‡å®šç§å­
  python run.py -s 12345 -r 2048 -t 55   # æŒ‡å®šæ‰€æœ‰å‚æ•°
  python run.py -m                       # å¤šç§å­æ¨¡å¼ï¼ˆéšæœºæœç´¢ï¼‰
        """,
    )
    parser.add_argument(
        "-s", "--seed",
        type=int,
        default=None,
        help="ä¸–ç•Œç§å­"
    )
    parser.add_argument(
        "-r", "--radius",
        type=int,
        default=None,
        help=f"åŒºå—æ£€æµ‹åŠå¾„ (é»˜è®¤: {DEFAULT_RADIUS}, æœ€å¤§: {MAX_RADIUS})"
    )
    parser.add_argument(
        "-t", "--threshold",
        type=int,
        default=None,
        help=f"è®¡æ•°é˜ˆå€¼ (é»˜è®¤: {DEFAULT_THRESHOLD}, æœ€å¤§: {MAX_SLIME_CHUNKS})"
    )
    parser.add_argument(
        "-m", "--multiple",
        action="store_true",
        help="å¤šç§å­æ¨¡å¼ï¼Œéšæœºæœç´¢ç§å­"
    )
    parser.add_argument(
        "-i", "--interactive",
        action="store_true",
        help="å¼ºåˆ¶ä½¿ç”¨äº¤äº’å¼æ¨¡å¼"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        help="ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­ï¼ˆå¤šç§å­æ¨¡å¼ï¼‰"
    )
    parser.add_argument(
        "--clear-checkpoint",
        action="store_true",
        help="æ¸…é™¤æ£€æŸ¥ç‚¹ï¼Œé‡æ–°å¼€å§‹"
    )
    parser.add_argument(
        "--no-warmup",
        action="store_true",
        help="è·³è¿‡å¯åŠ¨é¢„çƒ­ï¼ˆé¦–æ¬¡è¿è¡Œå¯èƒ½æ›´æ…¢ï¼‰"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼šä¸æ‰“å°æ¯ä¸ªå‘½ä¸­ï¼Œåªè¾“å‡ºæ‘˜è¦"
    )
    parser.add_argument(
        "--count-only",
        action="store_true",
        help="é«˜ååæ¨¡å¼ï¼šä»…ç»Ÿè®¡æ¯ä¸ªç§å­æ˜¯å¦å‘½ä¸­åŠæœ€ä½³è®¡æ•°ï¼Œä¸ä¿å­˜æ˜ç»†ç»“æœ"
    )
    return parser.parse_args()


def get_user_inputs(args: Optional[argparse.Namespace] = None) -> Tuple[Union[str, int], int, int]:
    """
    è·å–ç”¨æˆ·è¾“å…¥çš„è¿è¡Œæ¨¡å¼, æ£€æµ‹åŠå¾„å’Œè®¡æ•°é˜ˆå€¼
    æ”¯æŒå‘½ä»¤è¡Œå‚æ•°å’Œäº¤äº’å¼è¾“å…¥

    Args:
        args: å‘½ä»¤è¡Œå‚æ•°ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨äº¤äº’å¼è¾“å…¥

    Returns:
        tuple: æ¨¡å¼, æ£€æµ‹åŠå¾„, è®¡æ•°é˜ˆå€¼

    Raises:
        ValueError: å½“è¾“å…¥å€¼æ— æ•ˆæ—¶
    """
    # å¦‚æœæä¾›äº†å‘½ä»¤è¡Œå‚æ•°ä¸”ä¸æ˜¯äº¤äº’å¼æ¨¡å¼
    if args and not args.interactive:
        # ç¡®å®šæ¨¡å¼
        if args.multiple:
            mode = DEFAULT_MODE
        elif args.seed is not None:
            if not (MIN_SEED <= args.seed <= MAX_SEED):
                raise ValueError(f"ç§å­å€¼å¿…é¡»åœ¨ -2^63 åˆ° 2^63-1 ä¹‹é—´ï¼Œå½“å‰å€¼: {args.seed}")
            mode = args.seed
        else:
            # æ²¡æœ‰æŒ‡å®šç§å­ä¹Ÿæ²¡æœ‰æŒ‡å®šå¤šç§å­æ¨¡å¼ï¼Œä½¿ç”¨äº¤äº’å¼
            return get_user_inputs_interactive()

        # è·å–åŠå¾„
        if args.radius is not None:
            if args.radius <= 0:
                raise ValueError(f"æ£€æµ‹åŠå¾„å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå½“å‰å€¼: {args.radius}")
            if args.radius > MAX_RADIUS:
                raise ValueError(f"æ£€æµ‹åŠå¾„è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {MAX_RADIUS}ï¼Œå½“å‰å€¼: {args.radius}")
            radius = args.radius
        else:
            radius = DEFAULT_RADIUS

        # è·å–é˜ˆå€¼
        if args.threshold is not None:
            if args.threshold <= 0:
                raise ValueError(f"è®¡æ•°é˜ˆå€¼å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå½“å‰å€¼: {args.threshold}")
            if args.threshold > MAX_SLIME_CHUNKS:
                raise ValueError(f"è®¡æ•°é˜ˆå€¼è¿‡å¤§ï¼Œæœ€å¤§æœ‰æ•ˆå€¼ä¸º {MAX_SLIME_CHUNKS}ï¼Œå½“å‰å€¼: {args.threshold}")
            threshold = args.threshold
        else:
            threshold = DEFAULT_THRESHOLD

        return mode, radius, threshold

    # äº¤äº’å¼æ¨¡å¼
    return get_user_inputs_interactive()


def get_user_inputs_interactive() -> Tuple[Union[str, int], int, int]:
    """
    äº¤äº’å¼è·å–ç”¨æˆ·è¾“å…¥

    Returns:
        tuple: æ¨¡å¼, æ£€æµ‹åŠå¾„, è®¡æ•°é˜ˆå€¼

    Raises:
        ValueError: å½“è¾“å…¥å€¼æ— æ•ˆæ—¶
    """
    mode_input = (
        input(
            f"è¿è¡Œæ¨¡å¼, è®¡ç®—æ‰€æœ‰ç§å­(multiple seeds)æˆ–å•ä¸ªç§å­(single seed) ([{DEFAULT_MODE}]ultiple seeds/ç§å­å€¼):"
        )
        .strip()
        .upper()
    )

    if not mode_input or mode_input.startswith(DEFAULT_MODE):
        mode = DEFAULT_MODE
    else:
        try:
            mode = int(mode_input)
            if not (MIN_SEED <= mode <= MAX_SEED):
                raise ValueError(f"ç§å­å€¼å¿…é¡»åœ¨ -2^63 åˆ° 2^63-1 ä¹‹é—´ï¼Œå½“å‰å€¼: {mode}")
        except ValueError as e:
            if "ç§å­å€¼å¿…é¡»" in str(e):
                raise
            raise ValueError(f"æ— æ•ˆçš„ç§å­å€¼: {mode_input}ï¼Œè¯·è¾“å…¥æ•´æ•°æˆ– 'M'")

    radius_input = input(f"åŒºå—æ£€æµ‹åŠå¾„ [{DEFAULT_RADIUS}]:")
    if radius_input:
        try:
            radius = int(radius_input)
            if radius <= 0:
                raise ValueError(f"æ£€æµ‹åŠå¾„å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå½“å‰å€¼: {radius}")
            if radius > MAX_RADIUS:
                raise ValueError(f"æ£€æµ‹åŠå¾„è¿‡å¤§ï¼Œæœ€å¤§æ”¯æŒ {MAX_RADIUS}ï¼Œå½“å‰å€¼: {radius}")
        except ValueError as e:
            if "æ£€æµ‹åŠå¾„" in str(e):
                raise
            raise ValueError(f"æ— æ•ˆçš„æ£€æµ‹åŠå¾„: {radius_input}ï¼Œè¯·è¾“å…¥æ­£æ•´æ•°")
    else:
        radius = DEFAULT_RADIUS

    threshold_input = input(f"è®¡æ•°é˜ˆå€¼ [{DEFAULT_THRESHOLD}]:")
    if threshold_input:
        try:
            threshold = int(threshold_input)
            if threshold <= 0:
                raise ValueError(f"è®¡æ•°é˜ˆå€¼å¿…é¡»ä¸ºæ­£æ•´æ•°ï¼Œå½“å‰å€¼: {threshold}")
            if threshold > MAX_SLIME_CHUNKS:
                raise ValueError(f"è®¡æ•°é˜ˆå€¼è¿‡å¤§ï¼Œæœ€å¤§æœ‰æ•ˆå€¼ä¸º {MAX_SLIME_CHUNKS}ï¼Œå½“å‰å€¼: {threshold}")
        except ValueError as e:
            if "è®¡æ•°é˜ˆå€¼" in str(e):
                raise
            raise ValueError(f"æ— æ•ˆçš„è®¡æ•°é˜ˆå€¼: {threshold_input}ï¼Œè¯·è¾“å…¥æ­£æ•´æ•°")
    else:
        threshold = DEFAULT_THRESHOLD

    return mode, radius, threshold


def generate_seeds(mode: Union[str, int]) -> Generator[torch.Tensor, None, None]:
    """
    ç”Ÿæˆç”±æ¨¡å¼æ§åˆ¶çš„ç§å­, å¦‚æœæ˜¯multiple seedsæ¨¡å¼(str)åˆ™éšæœºç”Ÿæˆ, å¦åˆ™ä½¿ç”¨æ¨¡å¼æŒ‡å®šçš„ç§å­(ç§å­å€¼)

    Args:
        mode: æ¨¡å¼

    Yields:
        torch.Tensor: ç§å­å€¼
    """
    if mode == DEFAULT_MODE:
        while True:
            # ä½¿ç”¨ Python RNG ç”Ÿæˆï¼Œå†è½¬ Tensorï¼Œé¿å…é«˜é¢‘ torch.randint è°ƒç”¨å¼€é”€
            yield torch.tensor(
                random.randint(-(2**63), 2**63 - 1),
                dtype=torch.int64,
                device=device,
            )
    else:
        yield torch.tensor(mode, dtype=torch.int64, device=device)


def generate_seed_values(mode: Union[str, int]) -> Generator[int, None, None]:
    """
    ç”Ÿæˆ Python int ç±»å‹çš„ç§å­å€¼ï¼ˆç”¨äºå¤šç§å­é«˜é¢‘è°ƒåº¦ï¼Œå‡å°‘å¼ é‡æ„é€ å¼€é”€ï¼‰

    Args:
        mode: æ¨¡å¼

    Yields:
        int: ç§å­å€¼
    """
    if mode == DEFAULT_MODE:
        while True:
            yield random.randint(-(2**63), 2**63 - 1)
    else:
        yield int(mode)


def get_random_seed(
    worldSeed: torch.Tensor, chunkX: torch.Tensor, chunkZ: torch.Tensor
) -> torch.Tensor:
    """
    é€šè¿‡ä¸–ç•Œç§å­å’ŒåŒºå—åæ ‡è®¡ç®—éšæœºæ•°ç”Ÿæˆç§å­

    Args:
        worldSeed: ä¸–ç•Œç§å­
        chunkX: åŒºå—Xåæ ‡
        chunkZ: åŒºå—Zåæ ‡

    Returns:
        torch.Tensor: éšæœºæ•°ç§å­
    """
    return (
        worldSeed
        + (chunkX * chunkX * v1).to(dtype=torch.int64)
        + (chunkX * v2).to(dtype=torch.int64)
        + (chunkZ * chunkZ).to(dtype=torch.int64) * v3
        + (chunkZ * v4).to(dtype=torch.int64)
        ^ scrambler
    )


def next_int(seed: torch.Tensor) -> torch.Tensor:
    """
    æ¨¡æ‹Ÿ Java Random.nextInt(10) çš„è¡Œä¸ºï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰

    é‡è¯•æ¦‚ç‡çº¦ 2 äº¿åˆ†ä¹‹ä¸€ (10 / 2^31)ï¼Œä½†ä¸ºä¿è¯æ­£ç¡®æ€§å¿…é¡»å¤„ç†ã€‚
    ä½¿ç”¨çº¯å¼ é‡æ“ä½œï¼Œé¿å… Python æ¡ä»¶åˆ†æ”¯ï¼Œæ”¯æŒ torch.compile ä¼˜åŒ–ã€‚

    Args:
        seed: éšæœºæ•°ç§å­å¼ é‡

    Returns:
        torch.Tensor: 0-9 ä¹‹é—´çš„éšæœºæ•´æ•°
    """
    seed = (seed ^ multiplier) & mask

    # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼ˆ99.9999995% çš„æƒ…å†µä¸‹æœ‰æ•ˆï¼‰
    s1 = (seed * multiplier + addend) & mask
    u1 = (s1 >> 17).to(dtype=torch.int32)
    # å¤„ç†æœ‰ç¬¦å·æ•´æ•°ï¼šå¦‚æœæœ€é«˜ä½ä¸º 1ï¼Œåˆ™ä¸ºè´Ÿæ•°
    u1 = torch.where((u1 & (1 << 31)).bool(), u1 - (1 << 32), u1)
    r1 = u1 % 10
    valid1 = (u1 - r1 + 9) >= 0

    # ç¬¬äºŒæ¬¡è¿­ä»£ï¼ˆå¤„ç†æå°‘æ•°æ— æ•ˆæƒ…å†µï¼‰
    # å§‹ç»ˆè®¡ç®—ï¼Œä½†åªåœ¨éœ€è¦æ—¶ä½¿ç”¨ç»“æœï¼ˆé¿å…æ¡ä»¶åˆ†æ”¯ï¼‰
    s2 = (s1 * multiplier + addend) & mask
    u2 = (s2 >> 17).to(dtype=torch.int32)
    u2 = torch.where((u2 & (1 << 31)).bool(), u2 - (1 << 32), u2)
    r2 = u2 % 10

    # ä½¿ç”¨ torch.where åˆå¹¶ç»“æœï¼ˆæ— æ¡ä»¶åˆ†æ”¯ï¼‰
    return torch.where(valid1, r1, r2)


# æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ torch.compile
def _can_use_torch_compile() -> bool:
    """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ torch.compile with inductor"""
    if not torch.cuda.is_available():
        return False
    try:
        import triton
        # Triton 3.x+ ä½¿ç”¨æ–°çš„ API
        return hasattr(triton, 'compiler') and hasattr(triton.compiler, 'compile')
    except ImportError:
        return False


def _can_use_cudagraphs() -> bool:
    """æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ CUDA Graphs"""
    return torch.cuda.is_available()


_USE_TORCH_COMPILE = _can_use_torch_compile()
_USE_CUDAGRAPHS = _can_use_cudagraphs() and not _USE_TORCH_COMPILE


def _compute_slime_chunks_batch_impl(
    seed: torch.Tensor,
    x_coords: torch.Tensor,
    z_coords: torch.Tensor,
) -> torch.Tensor:
    """
    æ‰¹é‡è®¡ç®—å²è±å§†åŒºå—

    Args:
        seed: ä¸–ç•Œç§å­
        x_coords: X åæ ‡å¼ é‡
        z_coords: Z åæ ‡å¼ é‡

    Returns:
        torch.Tensor: æ˜¯å¦ä¸ºå²è±å§†åŒºå—çš„å¸ƒå°”å¼ é‡
    """
    seeds = get_random_seed(seed, x_coords, z_coords)
    return next_int(seeds) == 0


# ä½¿ç”¨ torch.compile ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ï¼‰
# æ³¨æ„ï¼šä¸ä½¿ç”¨ fullgraph=Trueï¼Œå› ä¸ºå†…éƒ¨å‡½æ•°ä½¿ç”¨äº† @torch.compiler.disable
if _USE_TORCH_COMPILE:
    _compute_slime_chunks_batch = torch.compile(
        _compute_slime_chunks_batch_impl,
        mode="reduce-overhead",
    )
elif _USE_CUDAGRAPHS:
    # Windows ä¸Šä½¿ç”¨ cudagraphs åç«¯ï¼ˆä¸ä¾èµ– Tritonï¼‰
    _compute_slime_chunks_batch = torch.compile(
        _compute_slime_chunks_batch_impl,
        backend="cudagraphs",
    )
else:
    _compute_slime_chunks_batch = _compute_slime_chunks_batch_impl


@torch.no_grad()
def detect_slime_chunk(
    seed: Union[int, torch.Tensor],
    chunk_radius: int,
    device: torch.device = device,
    block_size: int = BLOCK_SIZE,
    use_compiled: bool = True,
) -> Generator[Tuple[int, int, torch.Tensor], None, None]:
    """
    åˆ†å—è®¡ç®—å²è±å§†åŒºå—ï¼Œå¸¦é‡å ï¼Œé¿å… OOM ä¸”ä¿è¯å·ç§¯ç»“æœæ­£ç¡®

    Args:
        seed: ä¸–ç•Œç§å­
        chunk_radius: æ£€æµ‹åŠå¾„
        device: è®¡ç®—è®¾å¤‡
        block_size: æ¯ä¸ªåˆ†å—çš„æœ‰æ•ˆå¤§å°

    Yields:
        Tuple[int, int, torch.Tensor]: (x_offset, z_offset, chunk_tensor) åˆ†å—çš„å²è±å§†åŒºå—æ•°æ®
    """
    # ç¡®ä¿ seed æ˜¯ Tensor
    if not isinstance(seed, torch.Tensor):
        seed = torch.tensor(seed, dtype=torch.int64, device=device)

    compute_fn = _compute_slime_chunks_batch if use_compiled else _compute_slime_chunks_batch_impl

    overlap = 15 - 1
    total_size = 2 * chunk_radius + 1

    # å•å—å¿«é€Ÿè·¯å¾„ï¼šå½“æ€»åŒºåŸŸåªéœ€ä¸€ä¸ªåˆ†å—æ—¶ï¼Œé¿å…åŒå±‚å¾ªç¯ä¸è¾¹ç•Œè®¡ç®—å¼€é”€
    if total_size <= block_size:
        x_start, z_start, x_coords, z_coords = _get_single_block_coords(chunk_radius, device)
        chunks = compute_fn(seed, x_coords, z_coords)
        yield x_start, z_start, chunks
        return

    # ä½¿ç”¨ Python è®¡ç®—åæ ‡èŒƒå›´ï¼Œé¿å… GPU åŒæ­¥
    for i in range(0, total_size, block_size):
        for j in range(0, total_size, block_size):
            # ç›´æ¥ç”¨ Python è®¡ç®—èµ·å§‹åæ ‡
            x_start = -chunk_radius + i
            z_start = -chunk_radius + j
            
            # è®¡ç®—å—çš„å®é™…å¤§å°ï¼ˆåŒ…å«é‡å ï¼‰
            x_end = min(x_start + block_size + overlap, chunk_radius + 1)
            z_end = min(z_start + block_size + overlap, chunk_radius + 1)
            
            # åœ¨ GPU ä¸Šåˆ›å»ºåæ ‡å¼ é‡
            x_block = torch.arange(x_start, x_end, dtype=torch.int32, device=device)
            z_block = torch.arange(z_start, z_end, dtype=torch.int32, device=device)

            # ä½¿ç”¨å¹¿æ’­åæ ‡ï¼Œé¿å… meshgrid + flatten + reshape çš„é¢å¤–å¼€é”€
            # ç»“æœå½¢çŠ¶ä¸º [len(z_block), len(x_block)]ï¼Œä¸åŸå®ç°ä¿æŒä¸€è‡´
            x_coords = x_block.unsqueeze(0)
            z_coords = z_block.unsqueeze(1)
            chunks = compute_fn(seed, x_coords, z_coords)

            yield x_start, z_start, chunks


def detect_and_log_matches(
    chunk_tensor: torch.Tensor,
    threshold: int,
    x_start: int,
    z_start: int,
    seed: torch.Tensor,
    verbose: bool = True,
) -> None:
    """
    å¯¹è¾“å…¥çš„ chunk_tensor è¿›è¡Œå·ç§¯åŒ¹é…ï¼Œè‹¥åŒ¹é…å€¼ >= thresholdï¼Œåˆ™æ‰“å°åŒ¹é…ä½ç½®å’Œæ•°å€¼ã€‚

    Args:
        chunk_tensor: [H, W] çš„å¸ƒå°”æˆ–æ•´æ•°å¼ é‡ï¼Œè¡¨ç¤ºå½“å‰åˆ†å—çš„å²è±å§†åŒºå—
        threshold: åŒ¹é…é˜ˆå€¼
        x_start: å½“å‰å—åœ¨å…¨å±€ X æ–¹å‘çš„èµ·å§‹ç´¢å¼•åç§»
        z_start: å½“å‰å—åœ¨å…¨å±€ Z æ–¹å‘çš„èµ·å§‹ç´¢å¼•åç§»
        seed: å½“å‰ä¸–ç•Œç§å­ï¼ˆç”¨äºæ‰“å°ï¼‰
        verbose: æ˜¯å¦è¾“å‡ºè¯¦ç»†æ—¥å¿—
    """
    with torch.inference_mode():
        threshold_f = float(threshold)
        chunk_tensor = chunk_tensor[None, None]

        # ä½¿ç”¨é¢„è®¡ç®—çš„ FP16 patternï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if USE_FP16:
            chunk_tensor = chunk_tensor.half()
            conv_result = F.conv2d(chunk_tensor, PATTERN_FP16).float()
        else:
            chunk_tensor = chunk_tensor.float()
            conv_result = F.conv2d(chunk_tensor, PATTERN)

        # è®¡ç®—æœ‰æ•ˆåŒºåŸŸï¼Œé¿å…è¾¹ç•Œé—®é¢˜
        pattern_h, pattern_w = PATTERN.shape[-2], PATTERN.shape[-1]
        valid_h = conv_result.shape[-2] - (pattern_h - 1)
        valid_w = conv_result.shape[-1] - (pattern_w - 1)

        # å¦‚æœæœ‰æ•ˆåŒºåŸŸä¸ºç©ºï¼Œç›´æ¥è¿”å›
        if valid_h <= 0 or valid_w <= 0:
            return

        valid_result = conv_result[:, :, :valid_h, :valid_w]

        # å…ˆåšå—çº§æœ€å¤§å€¼ç­›é€‰ï¼Œæœªè¾¾é˜ˆå€¼æ—¶ç›´æ¥è·³è¿‡åç»­ argwhere ä¸ GPU->CPU ä¼ è¾“
        max_value = float(valid_result.max().item())
        if max_value < threshold_f:
            return

        count_only = is_count_only_mode()
        if count_only:
            # ä»…è®¡æ•°æ¨¡å¼ï¼šæœ€å¤§å€¼å·²çŸ¥ä¸” >= thresholdï¼Œç›´æ¥è®°å½•é¿å…æ„é€  match_mask ä¸å›ä¼ 
            seed_val = int(seed.item())
            update_count_only_seed_best(seed_val, int(max_value))
            return

        match_mask = valid_result >= threshold_f

        # è·å–æ‰€æœ‰åŒ¹é…ä½ç½®å’Œå€¼ï¼ˆä½¿ç”¨ argwhere æ¯” nonzero å¿« 30+ å€ï¼‰
        positions = torch.argwhere(match_mask[0, 0])  # [N, 2] tensor
        values = valid_result[0, 0][match_mask[0, 0]]

        # ä¸€æ¬¡æ€§è½¬ç§»åˆ° CPU
        positions_np = positions.cpu().numpy()
        values_np = values.cpu().numpy()
        seed_val = int(seed.item())
        spawn_radius = SPAWN_RADIUS
        ts_now = datetime.now().isoformat

        batched_results: List[Dict] = []
        log_messages: List[str] = []

        for (h, w), value in zip(positions_np, values_np):
            x = x_start + int(w) + spawn_radius
            z = z_start + int(h) + spawn_radius
            count = int(value)

            batched_results.append(
                {
                    "seed": seed_val,
                    "slime_chunks": count,
                    "afk_x": x,
                    "afk_z": z,
                    "timestamp": ts_now(),
                }
            )
            if verbose:
                log_messages.append(
                    f"å²è±å§†åŒºå—æ•°: {count}, ç§å­: {seed_val}, æŒ‚æœºç‚¹åŒºå—ä½ç½®: ({x}, {z})"
                )

        # ç»“æœæ‰¹é‡å…¥åº“ï¼Œå‡å°‘é”ç«äº‰
        add_results_batch(batched_results)

        # æ—¥å¿—æ‰¹é‡è¾“å‡º
        if log_messages:
            for msg in log_messages:
                log_and_print(msg)


def process_seed(
    seed: Union[int, torch.Tensor],
    threshold: int,
    chunk_radius: int,
    block_size: int = BLOCK_SIZE,
    use_compiled: bool = True,
) -> None:
    """
    å¤„ç†å•ä¸ªç§å­çš„å²è±å§†åŒºå—æ£€æµ‹

    Args:
        seed: ä¸–ç•Œç§å­
        threshold: åŒ¹é…é˜ˆå€¼
        chunk_radius: æ£€æµ‹åŠå¾„
        block_size: åˆ†å—å¤§å°ï¼ˆç”¨äºæ§åˆ¶å•æ¬¡ CUDA å·¥ä½œè´Ÿè½½ï¼‰
    """
    if not isinstance(seed, torch.Tensor):
        seed = torch.tensor(seed, dtype=torch.int64, device=device)
    else:
        seed = seed.to(device, dtype=torch.int64)

    # ğŸ“Œ ä¼˜åŒ–ï¼šç¼“å­˜ verbose æ ‡å¿—ï¼Œé¿å…æ¯ä¸ªå—éƒ½è°ƒç”¨ is_verbose_output() å‡½æ•°
    verbose = is_verbose_output()

    for x_start, z_start, chunk_tensor in detect_slime_chunk(
        seed, chunk_radius, block_size=block_size, use_compiled=use_compiled
    ):
        detect_and_log_matches(
            chunk_tensor,
            threshold,
            x_start,
            z_start,
            seed,
            verbose=verbose,
        )

    if is_count_only_mode():
        finalize_count_only_seed(int(seed.item()))


def warmup_cudagraphs(seed: int = 12345, chunk_radius: int = 10, full_pipeline: bool = False) -> None:
    """
    é¢„çƒ­ CUDA Graphsï¼Œè§¦å‘ torch.compile ç¼–è¯‘ç¼“å­˜ã€‚
    
    è¿™ä¼šæ‰§è¡Œä¸€æ¬¡å®Œæ•´çš„æ£€æµ‹æµç¨‹ï¼Œç¡®ä¿æ‰€æœ‰ CUDA å†…æ ¸éƒ½è¢«ç¼–è¯‘å¹¶ç¼“å­˜,
    é¿å…åç»­æ­£å¼è¿è¡Œæ—¶çš„ 20+ ç§’ç¼–è¯‘å¼€é”€ã€‚
    
    Args:
        seed: ç”¨äºé¢„çƒ­çš„ç§å­
        chunk_radius: ç”¨äºé¢„çƒ­çš„åŠå¾„
    """
    print("ğŸ”„ æ­£åœ¨é¢„çƒ­ CUDA Graphs...")
    torch.cuda.synchronize()
    start = time.perf_counter()
    
    seed_tensor = torch.tensor(seed, dtype=torch.int64, device=device)

    # æ‰§è¡Œä¸€æ¬¡æµç¨‹è§¦å‘ç¼–è¯‘ï¼šé»˜è®¤åªé¢„çƒ­è®¡ç®—è·¯å¾„ï¼Œé¿å…é¢å¤–å·ç§¯å¼€é”€
    block_count = 0
    for x_start, z_start, chunk_tensor in detect_slime_chunk(seed_tensor, chunk_radius):
        if full_pipeline:
            detect_and_log_matches(
                chunk_tensor,
                50,
                x_start,
                z_start,
                seed_tensor,
                verbose=False,
            )
        block_count += 1
    
    torch.cuda.synchronize()
    elapsed = time.perf_counter() - start
    mode = "å®Œæ•´æµæ°´çº¿" if full_pipeline else "è®¡ç®—è·¯å¾„"
    print(f"âœ… é¢„çƒ­å®Œæˆï¼ˆ{mode}ï¼‰ï¼({elapsed:.2f}s, {block_count} blocks)")
    if full_pipeline:
        clear_results()  # æ¸…é™¤é¢„çƒ­äº§ç”Ÿçš„ä¸´æ—¶ç»“æœ


def run(mode: Union[str, int], radius: int, threshold: int, resume: bool = False) -> None:
    chunk_radius = radius + SPAWN_RADIUS

    # åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå¯ç”¨æ–­ç‚¹ç»­ä¼ ï¼‰
    processed_seeds = load_checkpoint() if resume else set()
    if resume and processed_seeds:
        log_and_print(f"ğŸ“‚ ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼Œå·²è·³è¿‡ {len(processed_seeds)} ä¸ªç§å­")

    # å•ç§å­æ¨¡å¼ï¼šåŒæ­¥æ‰§è¡Œ
    if mode != DEFAULT_MODE:
        # å•ç§å­æ¨¡å¼é€šå¸¸åªæ‰§è¡Œä¸€æ¬¡å·ç§¯ï¼Œå…³é—­ benchmark é¿å…é¦–æ¬¡ç®—æ³•æœç´¢å¼€é”€
        cudnn_benchmark_prev = torch.backends.cudnn.benchmark
        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = False

        verbose = is_verbose_output()

        for seed in generate_seeds(mode):
            try:
                # é¢„è®¡ç®—æ€»å—æ•°
                total_chunks = (
                    (2 * chunk_radius + 1 + BLOCK_SIZE - 1) // BLOCK_SIZE
                ) ** 2

                # å•ç§å­å•å—ä»»åŠ¡ï¼šè·³è¿‡ torch.compile é¦–æ¬¡ç¼–è¯‘å¼€é”€ï¼ˆé€šå¸¸æ›´å¿«ï¼‰
                use_compiled = total_chunks > 1

                # åˆ›å»º tqdm è¿›åº¦æ¡ï¼Œæ˜¾ç¤ºå®Œæ•´è¿›åº¦
                with tqdm(
                    total=total_chunks,
                    desc=f"Processing seed {seed.item()}",
                    dynamic_ncols=True,
                    bar_format="{desc} | {percentage:3.0f}% | {n_fmt}/{total_fmt} blocks | {rate_fmt} | ETA: {remaining}",
                    leave=True,
                ) as pbar:
                    for x_start, z_start, chunk_tensor in detect_slime_chunk(
                        seed, chunk_radius, use_compiled=use_compiled
                    ):
                        detect_and_log_matches(
                            chunk_tensor,
                            threshold,
                            x_start,
                            z_start,
                            seed,
                            verbose=verbose,
                        )
                        pbar.update(1)  # æ‰‹åŠ¨æ›´æ–°è¿›åº¦
            except Exception:
                logging.exception("Error processing single seed")

        if torch.cuda.is_available():
            torch.backends.cudnn.benchmark = cudnn_benchmark_prev
        return

    # å¤šç§å­æ¨¡å¼ï¼šGPU ä¸²è¡Œå¤„ç†ï¼ˆé¿å… torch.compile + å¤šçº¿ç¨‹å¯¼è‡´å´©æºƒ/é€€åŒ–ï¼‰
    # è¯´æ˜ï¼šåœ¨å½“å‰ PyTorch + CUDA Graphs ç¯å¢ƒä¸‹ï¼Œçº¿ç¨‹å¹¶å‘ä¼šè§¦å‘ TLS æ–­è¨€é”™è¯¯ï¼Œ
    # ä¸”ååæ˜¾è‘—ä¸‹é™ï¼Œå› æ­¤æ”¹ä¸ºç¨³å®šçš„ä¸²è¡Œè°ƒåº¦ã€‚
    log_and_print("âš™ï¸ å¤šç§å­è°ƒåº¦æ¨¡å¼: GPU ä¸²è¡Œ")

    with tqdm(
        desc="Processing seeds",
        dynamic_ncols=True,
        bar_format="{desc} | {rate_fmt} | Total: {n_fmt}",
    ) as pbar:
        skipped_count = 0
        for seed_val in generate_seed_values(mode):
            # è·³è¿‡å·²å¤„ç†çš„ç§å­
            if seed_val in processed_seeds:
                skipped_count += 1
                if skipped_count % 1000 == 0:
                    pbar.set_postfix_str(f"skipped={skipped_count}")
                continue

            try:
                process_seed(
                    seed_val,
                    threshold,
                    chunk_radius,
                    use_compiled=True,
                )
                # ä¿å­˜æ£€æŸ¥ç‚¹
                save_checkpoint(seed_val)
                flush_checkpoints()
            except torch.cuda.OutOfMemoryError:
                logging.error(f"GPU å†…å­˜ä¸è¶³å¤„ç†ç§å­ {seed_val}ï¼Œå°è¯•æ¸…ç†ç¼“å­˜åç»§ç»­")
                torch.cuda.empty_cache()
            except RuntimeError as e:
                if "CUDA" in str(e) or "out of memory" in str(e).lower():
                    logging.error(f"CUDA é”™è¯¯å¤„ç†ç§å­ {seed_val}: {e}")
                    torch.cuda.empty_cache()
                else:
                    logging.exception(f"è¿è¡Œæ—¶é”™è¯¯å¤„ç†ç§å­ {seed_val}")
            except Exception:
                logging.exception(f"æœªçŸ¥é”™è¯¯å¤„ç†ç§å­ {seed_val}")
            finally:
                pbar.update(1)


def main() -> None:
    init_logging()

    log_and_print(f"Torch use device: {device}")
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_mem = torch.cuda.mem_get_info()[1] / 1024 / 1024 / 1024
        log_and_print(f"GPU: {gpu_name} ({gpu_mem:.1f} GB)")

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_args()
    set_verbose_output(not args.quiet)
    set_count_only_mode(args.count_only)
    if args.count_only:
        clear_count_only_stats()

    try:
        mode, radius, threshold = get_user_inputs(args)
    except ValueError as e:
        print(f"âŒ è¾“å…¥é”™è¯¯: {e}")
        sys.exit(1)

    log_and_print(
        f"mode or single seed number = {'multiple seeds' if mode == DEFAULT_MODE else mode}\nradius = {radius}\nthreshold = {threshold}"
    )

    # å¤„ç†æ£€æŸ¥ç‚¹é€‰é¡¹
    if args.clear_checkpoint:
        clear_checkpoint()
        log_and_print("ğŸ—‘ï¸ æ£€æŸ¥ç‚¹å·²æ¸…é™¤")

    if torch.cuda.is_available() and should_warmup(args):
        # é»˜è®¤åªé¢„çƒ­è®¡ç®—è·¯å¾„ï¼Œæ›´å¿«ï¼›å®Œæ•´æµæ°´çº¿åœ¨åŸºå‡†è„šæœ¬ä¸­å•ç‹¬é¢„çƒ­
        try:
            warmup_cudagraphs(full_pipeline=False)
        except Exception:
            logging.exception("CUDA warmup failed, continue without warmup")

    try:
        run(mode, radius, threshold, resume=args.resume)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨é€€å‡º...")
        logging.info("Program interrupted by user.")
    except Exception:
        logging.exception("Unexpected error in main")
    finally:
        # å¼ºåˆ¶åˆ·å†™æ£€æŸ¥ç‚¹ï¼Œä¿è¯ä¸­æ–­/å¼‚å¸¸ä¹Ÿä¸ä¸¢è¿›åº¦
        flush_checkpoints(force=True)

        # æ˜¾ç¤ºç»“æœæ‘˜è¦
        summary = get_results_summary()
        if summary['count'] > 0:
            log_and_print(f"\nğŸ“ˆ ç»“æœç»Ÿè®¡:")
            log_and_print(f"   æ€»ç»“æœæ•°: {summary['count']}")
            log_and_print(f"   æœ€é«˜å²è±å§†åŒºå—æ•°: {summary['max']}")
            log_and_print(f"   å¹³å‡å²è±å§†åŒºå—æ•°: {summary['avg']:.1f}")
            log_and_print(f"   æ¶‰åŠç§å­æ•°: {summary['unique_seeds']}")

            # æ˜¾ç¤º Top 5 ç»“æœ
            top_results = get_top_results(5)
            if top_results:
                log_and_print(f"\nğŸ† Top 5 ç»“æœ:")
                for i, r in enumerate(top_results, 1):
                    log_and_print(f"   {i}. ç§å­ {r['seed']}: {r['slime_chunks']} åŒºå— @ ({r['afk_x']}, {r['afk_z']})")

        if is_count_only_mode():
            count_summary = get_count_only_summary()
            log_and_print("\nâš¡ ä»…è®¡æ•°æ¨¡å¼ç»Ÿè®¡:")
            log_and_print(f"   å·²å¤„ç†ç§å­æ•°: {count_summary['processed_seeds']}")
            log_and_print(f"   å‘½ä¸­ç§å­æ•°: {count_summary['hit_seeds']}")
            log_and_print(f"   å‘½ä¸­ç‡: {count_summary['hit_rate'] * 100:.2f}%")
            log_and_print(f"   æœ€ä½³å‘½ä¸­è®¡æ•°: {count_summary['best_count']}")

        # ä¿å­˜ç»“æœåˆ° CSVï¼ˆcount-only æ¨¡å¼ä¸ä¿å­˜æ˜ç»†ï¼‰
        if not is_count_only_mode():
            csv_path = save_results_to_csv()
            if csv_path:
                log_and_print(f"\nğŸ“Š ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
        logging.shutdown()


if __name__ == "__main__":
    main()
